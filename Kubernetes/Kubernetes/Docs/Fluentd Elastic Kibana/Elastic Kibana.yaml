
#通过在每台node上部署一个以DaemonSet方式运行的fluentd来收集每台node上的日志。
#Fluentd将docker日志目录/var/lib/docker/containers和/var/log目录挂载到Pod中，然后Pod会在node节点的/var/log/pods目录中创建新的目录
#可以区别不同的容器日志输出，该目录下有一个日志文件链接到/var/lib/docker/contianers目录下的容器日志输出。


#下载资源清单：
for i in es-service.yaml es-statefulset.yaml fluentd-es-configmap.yaml fluentd-es-ds.yaml kibana-deployment.yaml kibana-service.yaml
do 
  wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/$i
done

#修改资源清单：
sed -i 's/k8s.gcr.io/mirrorgooglecontainers/g' es-statefulset.yaml
sed -i 's/k8s.gcr.io/mirrorgooglecontainers/g' fluentd-es-ds.yaml
sed -i -e 's@.*SERVER_BASEPATH.*@#&@g' -e 's@.*/api/v1/namespaces/kube-system/services/kibana-logging/proxy@#&@g' kibana-deployment.yaml
sed -i 's/v6.2.5/v6.3.0/g' es-statefulset.yaml

#持久存储日志：
sed -i -e 's/emptyDir: {}/hostPath:/g' -e '/hostPath/a\          path: /es-logdata\n          type: DirectoryOrCreate'   es-statefulset.yaml

#修改集群属性
kubectl label nodes --all beta.kubernetes.io/fluentd-ds-ready=true
kubectl taint nodes --all node-role.kubernetes.io/master-

#重新制作fluentd-elasticsearch镜像
for i in Dockerfile Gemfile Makefile README.md clean-apt clean-install fluent.conf run.sh
do 
  wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/cluster/addons/fluentd-elasticsearch/fluentd-es-image/$i
done

chmod +x clean-apt clean-install run.sh && docker build -t fluentd-elasticsearch:v2.2.0  .

#最终的资源清单文件：( 修改后 )
--- #es-service.yaml
apiVersion: v1
kind: Service                   #ES集群所有节点的负载地址 eg：elasticsearch-logging.kube-system.svc.cluster.local
metadata:
  name: elasticsearch-logging   #服务名称
  namespace: kube-system
  labels:
    k8s-app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "Elasticsearch"
spec:
  ports:
  - port: 9200                  #代理的ES端口地址，使用DNS的SRV记录能够请求到
    protocol: TCP
    targetPort: db              #容器中containerPort的name指定的端口标识 ( Pod中ES的9200端口 )
  selector:
    k8s-app: elasticsearch-logging    #标签选择所有ES节点

--- #创建ES使用的 ServiceAccount、ClusterRole、ClusterRoleBinding

apiVersion: v1
kind: ServiceAccount            #指定ES集群中的Pod使用的ServiceAccount账号
metadata:
  name: elasticsearch-logging   #账号名称elasticsearch-logging
  namespace: kube-system        #账号所属名称空间
  labels:
    k8s-app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole               #集群级别的Role资源对象
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: elasticsearch-logging   #定义名为elasticsearch-logging的集群级别Role
  labels:
    k8s-app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - ""
  resources:
  - "services"
  - "namespaces"
  - "endpoints"
  verbs:
  - "get"
---
kind: ClusterRoleBinding        #将ServiceAccount资源的elasticsearch-logging账号与ClusterRole资源的elasticsearch-logging规则进行绑定
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: kube-system
  name: elasticsearch-logging
  labels:
    k8s-app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
- kind: ServiceAccount
  name: elasticsearch-logging
  namespace: kube-system
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: elasticsearch-logging
  apiGroup: ""

--- # Elasticsearch StatefulSet deployment itself

apiVersion: apps/v1
kind: StatefulSet               #以有状态的方式部署Elastic
metadata:
  name: elasticsearch-logging   #StatefulSet资源的实例对象名称：elasticsearch-logging 
  namespace: kube-system        #属于集群级别的名称空间
  labels:
    k8s-app: elasticsearch-logging
    version: v6.6.1
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  serviceName: elasticsearch-logging    #即使用StatefulSet时通过DNS查找时的服务名
  replicas: 2
  selector:
    matchLabels:
      k8s-app: elasticsearch-logging    #仅运行在打了如下标签的节点中
      version: v6.6.1
  template:
    metadata:
      labels:
        k8s-app: elasticsearch-logging
        version: v6.6.1
        kubernetes.io/cluster-service: "true"
    spec:
      serviceAccountName: elasticsearch-logging   #本Pod使用的serviceAccountName账号
      containers:
      - image: gcr.io/fluentd-elasticsearch/elasticsearch:v6.6.1  #镜像地址
        name: elasticsearch-logging
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        ports:
        - containerPort: 9200       #HTTP Restful API
          name: db
          protocol: TCP
        - containerPort: 9300       #TCP
          name: transport
          protocol: TCP
        volumeMounts:
        - name: elasticsearch-logging     #Elastic 数据挂载点
          mountPath: /data
        env:
        - name: "NAMESPACE"               #从Pod中的元数据信息中读取并传递给Pod环境变量：NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
      volumes:
      - name: elasticsearch-logging
        emptyDir: {}
      # Elasticsearch requires vm.max_map_count to be at least 262144. If your OS already sets up this number to a higher value, feel free
      # to remove this init container.
      initContainers:                   #在容器初始化时修改内核参数
      - image: alpine:3.6
        command: ["/sbin/sysctl", "-w", "vm.max_map_count=262144"]
        name: elasticsearch-logging-init
        securityContext:
          privileged: true

--- #Fluentd的部署请查看同级目录的：Fluentd.yaml

--- #kibana-deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana-logging
  namespace: kube-system      #Kibana所属的集群名称为 "kube-system"
  labels:
    k8s-app: kibana-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: kibana-logging
  template:
    metadata:
      labels:
        k8s-app: kibana-logging
      annotations:
        seccomp.security.alpha.kubernetes.io/pod: 'docker/default'
    spec:
      containers:
      - name: kibana-logging
        image: docker.elastic.co/kibana/kibana-oss:6.3.2
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        env:
          - name: ELASTICSEARCH_URL   #指定Elastic的地址信息
            value: http://elasticsearch-logging:9200
#         - name: SERVER_BASEPATH
#           value: /api/v1/namespaces/kube-system/services/kibana-logging/proxy
        ports:
        - containerPort: 5601         #对外服务的端口
          name: ui
          protocol: TCP

--- #kibana-deployment.yaml

apiVersion: v1
kind: Service       #定义Kibana的服务域名
metadata:
  name: kibana-logging
  namespace: kube-system
  labels:
    k8s-app: kibana-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "Kibana"
spec:
  ports:
  - port: 5601
    protocol: TCP
    targetPort: ui
  selector:
    k8s-app: kibana-logging